{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa7b945-69b1-49fa-9991-1ba81a32e4f2",
   "metadata": {},
   "source": [
    "## 1. Scraping Current Subreddits for Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210adbc-cc13-41b1-8aad-821808295428",
   "metadata": {},
   "source": [
    "This notebook \n",
    "1. Scraps the top posts from the wallstreetbets subreddit currently\n",
    "2. Creates a frequency table of unique words and number of mentions\n",
    "3. Scraps the top level comments from the daily discussion thread\n",
    "4. Scraps the top comments from the 'what are you moves\" thread\n",
    "5. Outputs a csv with the frequency of ticker mentions\n",
    "6. Applies a sentiment analyzer to the comments\n",
    "7. Outputs a csv with the polarity of tickers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640b016-3e10-410f-b7fa-1381d1626281",
   "metadata": {},
   "source": [
    "#### Importing Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "592b86b4-e062-49a7-8d2f-34191b5abb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import re\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505529e1-f85a-4d6a-8042-65c73204c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude common words from analysis\n",
    "exclude_words = (['VERY','A','B','GO','ARE','ON','FOR','THE','TO',' ','SO','IT','AT','BE','OR','SO','ALL','HAS','BY','CAN','AN','OUT','NOW'])\n",
    "\n",
    "# Set to current time\n",
    "current_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8724568b-8ff9-4936-836d-ef27c0d0ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Reddit Client for Requests \n",
    "load_dotenv() \n",
    "client_id = os.environ['CLIENT_ID']\n",
    "client_secret = os.environ['CLIENT_SECRET']\n",
    "user_agent = os.environ['USER_AGENT']\n",
    "\n",
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e977109e-3230-4ba3-9e75-3fb77a95dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create a frequency table of the scraped comments\n",
    "def frequency_table_comments(clean):\n",
    "    for (index, row) in clean.iterrows(): # iterate over dataframe\n",
    "  # titles \n",
    "        title = row['comments'].upper() # get title in lowercase\n",
    "        title = regex.sub('', title)  # clean with reges\n",
    "        title_words = title.split(' ') # split titles at whitespace\n",
    "    for words in title_words:\n",
    "        if x in exclude_words: # common words that are also stock tickers or uneccesary. \n",
    "            word_dict[x] += 1\n",
    "        else:\n",
    "            word_dict[x] = 1\n",
    "    return pd.DataFrame.from_dict(list(word_dict.items())).rename(columns = {0:\"Term\", 1:\"Frequency\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4157dc1f-d491-4122-add3-b861f4e843b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining funtion to append comments to a list and creating a dataframe from them\n",
    "def appending_to_list(submission):\n",
    "    comments= []\n",
    "    for top_level_comment in submission.comments[:-1]: #leaving out the last comment, since it creates an error\n",
    "        comments.append(top_level_comment.body) # append comment to list\n",
    "# return dataframe of the list\n",
    "    return DataFrame(comments,columns=['comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83bcc5-3aee-4df6-8844-1f0c2a6fc889",
   "metadata": {},
   "source": [
    "### 1.1 Scrape current posts into dataframe.\n",
    "Scapes the current hot, new, and top posts in the wallstreetbets subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a09199f-1794-4e54-b79a-d9d48f24964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting posts into a dataframe\n",
    "df = [] # define empty list that will hold dictionarys\n",
    "#scraper =     \n",
    "for post in reddit.subreddit('wallstreetbets').hot(limit=500): # call wallstreetbets subreddit \"hot\" section and get first 1000 posts\n",
    "    content = {  # create dictionary for results\n",
    "    \"title\" : post.title, # store title\n",
    "    \"text\" : post.selftext # store text of the post\n",
    "    }\n",
    "    df.append(content) # append dataframe\n",
    "for post in reddit.subreddit('wallstreetbets').new(limit=2000): # call wallstreetbets subreddit \"new\" section and get first 1000 posts\n",
    "    content = {  # create dictionary for results\n",
    "    \"title\" : post.title, # store title\n",
    "    \"text\" : post.selftext # store text of the post\n",
    "    }\n",
    "    df.append(content) # append dataframe\n",
    "for post in reddit.subreddit('wallstreetbets').top(limit=500): # call wallstreetbets subreddit \"top\" section and get first 1000 posts\n",
    "    content = {  # create dictionary for results\n",
    "    \"title\" : post.title, # store title\n",
    "    \"text\" : post.selftext # store text of the post\n",
    "    }\n",
    "    df.append(content) # append dataframe\n",
    "    df_posts = pd.DataFrame(df) # convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8d58e-f972-4324-bb48-9073f4eabf2c",
   "metadata": {},
   "source": [
    "### 1.2 Create frequency table of unique words and the number of their mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14bb389b-0736-4851-bbf2-dd80ea908266",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile('[^a-zA-Z ]') # remove everything thats not a letter or space aka numbers and emojis\n",
    "word_dict = {} # create dictionary\n",
    "for (index, row) in df_posts.iterrows(): # iterate over dataframe\n",
    "  # titles \n",
    "    title = row['title'].upper() # get title in lowercase\n",
    "    title = regex.sub('', title)  # clean with reges\n",
    "    title_words = title.split(' ') # split titles at whitespace\n",
    "  # content\n",
    "    content = row['text'].upper() # get text from post in lowercase\n",
    "    content = regex.sub('', content) # clean with regex\n",
    "    content_words = content.split(' ') # split titles at whitespace\n",
    "  # combine titles and comments\n",
    "    words = title_words + content_words\n",
    "    for x in words:\n",
    "        if x in exclude_words:\n",
    "            pass\n",
    "        elif x in word_dict:\n",
    "            word_dict[x] += 1\n",
    "        else:\n",
    "            word_dict[x] = 1\n",
    "posts_freq= pd.DataFrame.from_dict(list(word_dict.items())).rename(columns = {0:\"Term\", 1:\"Frequency\"})\n",
    "# We now have a frequency table of the most often used words in the top 500 hot posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bf1ea-1ab6-4ea7-987f-79b97f3128af",
   "metadata": {},
   "source": [
    "### 1.3 Scraping the top level comments from the daily discussion thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c21d8cf5-42f3-40b4-ae63-45873501c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append these comments to a list\n",
    "daily_comments= [] # create empty list\n",
    "for top_level_comment in submission.comments[:-1]: #leaving out the last comment, since it creates an error\n",
    "        daily_comments.append(top_level_comment.body) # append comment to list\n",
    "len(daily_comments)\n",
    "\n",
    "# create dataframe of the comments\n",
    "df_comments = DataFrame(daily_comments,columns=['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f928e557-386a-43e5-a89c-4ff14a6efa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get comments of daily discussion thread\n",
    "url = (\"https://www.reddit.com/r/wallstreetbets/comments/n9th6n/daily_discussion_thread_for_\"+\n",
    "str(current_time.strftime(\"%B\")).lower() + \"_\"+  # constructing the link with daytime function\n",
    "str(current_time.strftime(\"%d\")).lower() +\"_\" +  # since this post is created new on a daily basis\n",
    "str(current_time.strftime(\"%Y\")).lower() + \"/\")  # Month, day, year\n",
    "\n",
    "submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c908a1b-dc60-4947-be73-833040c320e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = appending_to_list(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "394c2102-b889-454b-ad92-887b03e9d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling cleaning/splitting function to create frequency table\n",
    "comments_freq = frequency_table_comments(df_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9242b-0f8a-4181-af5d-42773dd1414c",
   "metadata": {},
   "source": [
    "### 1.4 Scraping the \"what are your moves\" thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc2a2c6b-7273-4f37-bec0-f338a07752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get comments of daily discussion thread\n",
    "url = (\"https://www.reddit.com/r/wallstreetbets/comments/n9eiyu/what_are_your_moves_tomorrow_\"+\n",
    "str(current_time.strftime(\"%B\")).lower() + \"_\"+  # constructing the link with daytime function\n",
    "str(current_time.strftime(\"%d\")).lower() +\"_\" +  # since this post is created new on a daily basis\n",
    "str(current_time.strftime(\"%Y\")).lower() + \"/\")  # Month, day, year\n",
    "submission = reddit.submission(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53089f35-96b3-4ab7-8127-ca1c148f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments_move = appending_to_list(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b0d6ebd-5773-438e-99e9-14e5fadcb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling cleaning/splitting function from above\n",
    "moves_freq = frequency_table_comments(df_comments_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32d2dd5b-c671-4670-a2b5-82a2d4ea4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all frequency tables on the term, performing an inner join \n",
    "merged_table = pd.merge(pd.merge(posts_freq,comments_freq,on='Term', how='left'),moves_freq,on='Term', how = 'left')\n",
    "# replace NA#s with zeros\n",
    "merged_table = merged_table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a478a4bc-2c36-4b53-802f-b3ed35c52c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating overall frequency in a new column\n",
    "merged_table['frequency']=merged_table['Frequency_x'] + merged_table['Frequency_y'] + merged_table['Frequency']\n",
    "# drop unnecessary frequency columns, only keeping the main one\n",
    "merged_table = merged_table.drop(['Frequency_x', 'Frequency_y', 'Frequency'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4c33bab-c684-4ca7-988e-284723ed7b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies Inc. Common Stock</td>\n",
       "      <td>Capital Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation Common Stock</td>\n",
       "      <td>Basic Industries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>Ares Acquisition Corporation Class A Ordinary ...</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA Creativity Global American Depositary Shares</td>\n",
       "      <td>Miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACQ</td>\n",
       "      <td>Artius Acquisition Inc. Class A Common Stock</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7636</th>\n",
       "      <td>ZWRKW</td>\n",
       "      <td>Z-Work Acquisition Corp. Warrant</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>ZY</td>\n",
       "      <td>Zymergen Inc. Common Stock</td>\n",
       "      <td>Basic Industries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>Zymeworks Inc. Common Shares</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>Zynerba Pharmaceuticals Inc. Common Stock</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex Inc. Common Stock</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7641 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Term                                       Company_Name  \\\n",
       "0         A             Agilent Technologies Inc. Common Stock   \n",
       "1        AA                    Alcoa Corporation Common Stock    \n",
       "2       AAC  Ares Acquisition Corporation Class A Ordinary ...   \n",
       "3      AACG   ATA Creativity Global American Depositary Shares   \n",
       "4      AACQ       Artius Acquisition Inc. Class A Common Stock   \n",
       "...     ...                                                ...   \n",
       "7636  ZWRKW                   Z-Work Acquisition Corp. Warrant   \n",
       "7637     ZY                         Zymergen Inc. Common Stock   \n",
       "7638   ZYME                       Zymeworks Inc. Common Shares   \n",
       "7639   ZYNE          Zynerba Pharmaceuticals Inc. Common Stock   \n",
       "7640   ZYXI                            Zynex Inc. Common Stock   \n",
       "\n",
       "                Sector  \n",
       "0        Capital Goods  \n",
       "1     Basic Industries  \n",
       "2              Finance  \n",
       "3        Miscellaneous  \n",
       "4              Finance  \n",
       "...                ...  \n",
       "7636           Finance  \n",
       "7637  Basic Industries  \n",
       "7638               NaN  \n",
       "7639       Health Care  \n",
       "7640       Health Care  \n",
       "\n",
       "[7641 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing a tickerlist from the nasdaq\n",
    "ticker_df = pd.read_csv('NasdaqTickers.csv', index_col=None, delimiter=';').rename(columns = {\"Symbol\":\"Term\", \"Name\":\"Company_Name\"})\n",
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "05509e9c-970f-4dc3-836c-561c2a88fea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AM</td>\n",
       "      <td>534</td>\n",
       "      <td>Antero Midstream Corporation Common Stock</td>\n",
       "      <td>Public Utilities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TH</td>\n",
       "      <td>168</td>\n",
       "      <td>Target Hospitality Corp. Common Stock</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI</td>\n",
       "      <td>312</td>\n",
       "      <td>C3.ai Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPEN</td>\n",
       "      <td>174</td>\n",
       "      <td>Opendoor Technologies Inc Common Stock</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOVE</td>\n",
       "      <td>180</td>\n",
       "      <td>Movano Inc. Common Stock</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>BAND</td>\n",
       "      <td>3</td>\n",
       "      <td>Bandwidth Inc. Class A Common Stock</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>MN</td>\n",
       "      <td>3</td>\n",
       "      <td>Manning &amp; Napier Inc. Class A Common Stock</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>YY</td>\n",
       "      <td>3</td>\n",
       "      <td>JOYY Inc. American Depositary Shares</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>PRPL</td>\n",
       "      <td>3</td>\n",
       "      <td>Purple Innovation Inc. Common Stock</td>\n",
       "      <td>Consumer Durables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>BCE</td>\n",
       "      <td>3</td>\n",
       "      <td>BCE Inc. Common Stock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Term  frequency                                Company_Name  \\\n",
       "0      AM        534   Antero Midstream Corporation Common Stock   \n",
       "1      TH        168       Target Hospitality Corp. Common Stock   \n",
       "2      AI        312             C3.ai Inc. Class A Common Stock   \n",
       "3    OPEN        174      Opendoor Technologies Inc Common Stock   \n",
       "4    MOVE        180                    Movano Inc. Common Stock   \n",
       "..    ...        ...                                         ...   \n",
       "502  BAND          3         Bandwidth Inc. Class A Common Stock   \n",
       "503    MN          3  Manning & Napier Inc. Class A Common Stock   \n",
       "504    YY          3        JOYY Inc. American Depositary Shares   \n",
       "505  PRPL          3         Purple Innovation Inc. Common Stock   \n",
       "506   BCE          3                       BCE Inc. Common Stock   \n",
       "\n",
       "                Sector  \n",
       "0     Public Utilities  \n",
       "1               Energy  \n",
       "2           Technology  \n",
       "3              Finance  \n",
       "4          Health Care  \n",
       "..                 ...  \n",
       "502         Technology  \n",
       "503            Finance  \n",
       "504         Technology  \n",
       "505  Consumer Durables  \n",
       "506                NaN  \n",
       "\n",
       "[507 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging tickerlist with mentions on reddit, inner join, so we will loose all words that are not tickers and all tickers that arent mentioned\n",
    "stocks_df = pd.merge(merged_table, ticker_df, on=\"Term\")\n",
    "stocks_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87841337-3858-45b4-967d-6d6c8a186258",
   "metadata": {},
   "source": [
    "### 1.5 Output ticker Frequency CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "951e7614-96d9-4afc-bdbc-0f03c0d4150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency data to csv \n",
    "stocks_df.to_csv('frequency_of_tickers_' + str(current_time.strftime(\"%d\"))+'_'+str(current_time.strftime(\"%m\"))+ '_'+ str(current_time.strftime(\"%H\"))+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f6ba1-fffc-46b4-b23b-bf882e72f0f6",
   "metadata": {},
   "source": [
    "### 1.6 Analyzing Sentiment in comments for tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80208a80-4433-41f2-9ba7-3c8b3d13999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of tickers that are in the above dataframe\n",
    "tickers = ticker_df['Term'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "806c30cb-516c-4aeb-884b-5ff963bdd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Vader to analyse social media sentiment better than with nltk\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1567ef11-02a6-4c4f-b83e-0e18478bb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    try:\n",
    "        scores = sia.polarity_scores(text)\n",
    "        return  scores['compound']\n",
    "    except: return none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31732892-2b9a-482c-99dd-977bc55ebcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add polarity column to posts\n",
    "df_posts['polarity'] = df_posts['text'].apply(sentiment)\n",
    "# drop title column\n",
    "df_posts = df_posts.drop(['title'], axis=1)\n",
    "# add polarity column \n",
    "df_comments['polarity'] = df_comments['comments'].apply(sentiment)\n",
    "df_comments_move['polarity'] = df_comments_move['comments'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "898e2095-5571-47f2-93d2-470043e083d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of the three dataframes to make iterating for sentiment extraction easier\n",
    "list_df = [df_posts, df_comments, df_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e404f34d-8160-43e7-90d7-6acc813555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting sentiment and associated ticker out of the dataframe\n",
    "sentiment_to_df= [] # list for sentiment score\n",
    "tickers_to_df = [] # list for tickers\n",
    "\n",
    "for dataframe in list_df: \n",
    "    for index, row in dataframe.iterrows(): # for every row in dataframe\n",
    "        title_words = row[0].split(' ') # split comment at whitespace and put into list\n",
    "        for word in title_words:\n",
    "            if word in tickers: \n",
    "                tickers_to_df.append(word) # append the word to the word list\n",
    "                sentiment_to_df.append(row[1]) # append the sentiment to the sentiment list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c14e88ed-d6be-4c71-9738-8660c15b6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentiment dataframe \n",
    "sentiment_df1 = pd.DataFrame(list(zip(tickers_to_df, sentiment_to_df)),\n",
    "              columns =['Term', 'Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0935bf7-a2ab-4820-bffa-f629070362da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355886</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.901737</td>\n",
       "      <td>AI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998500</td>\n",
       "      <td>ALK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.340000</td>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.996900</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.973100</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.075800</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.255557</td>\n",
       "      <td>ZIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.900900</td>\n",
       "      <td>ZM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Polarity  Term\n",
       "0    0.355886     A\n",
       "1    0.000000  AAPL\n",
       "2    0.901737    AI\n",
       "3    0.998500   ALK\n",
       "4   -0.340000   ALL\n",
       "..        ...   ...\n",
       "169  0.996900   XOM\n",
       "170  0.973100     Y\n",
       "171  0.075800     Z\n",
       "172  0.255557   ZIM\n",
       "173  0.900900    ZM\n",
       "\n",
       "[174 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group table by ticker, get mean of sentiment, create new dataframe with new index\n",
    "sentiment_table=sentiment_df1.groupby(['Term']).mean()\n",
    "sentiment_table['Term'] = sentiment_table.index\n",
    "sentiment_table=sentiment_table.reset_index(drop=True)\n",
    "sentiment_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106f2d4-7551-43d4-959c-fb1d98536f53",
   "metadata": {},
   "source": [
    "### 1.7 Output CSV with Polarity Score for each ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b41ba49c-90ff-44d0-a960-33fdedfac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "sentiment_table.to_csv('sentiment_of_tickers_' + str(current_time.strftime(\"%d\"))+'_'+str(current_time.strftime(\"%m\"))+ '_'+ str(current_time.strftime(\"%H\"))+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
